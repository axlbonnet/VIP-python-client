{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Jobs from your Computer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../imgs/Upload_Run_Download.png\" alt=\"Procedure\" height=\"250\" title=\"Procedure for the Python Client\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from src.VipSession import VipSession\n",
    "from pathlib import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate your Session "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*API key is provided in your VIP account settings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------\n",
      "| You are communicating with VIP |\n",
      "----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VipSession.init(api_key=\"VIP_API_KEY\"); # Paste your VIP API key here\n",
    "# N.B.: API key can be stored in an environment variable, in a file or written as litteral string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SESSION 'demo-single-job' ===\n",
      "\n",
      "Output directory: vip_outputs/demo-single-job\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a Session with a name\n",
    "my_session = VipSession(\"demo-single-job\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload your dataset on VIP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload a single folder containing the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mdata/quest_1job\u001b[0m\n",
      "├── \u001b[01;31mbasis.zip\u001b[0m\n",
      "├── parameters.txt\n",
      "└── signal.mrui\n",
      "\n",
      "0 directories, 3 files\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"data/quest_1job\"\n",
    "! tree {input_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== UPLOAD INPUTS ===\n",
      "\n",
      "Input Directory: 'data/quest_1job' --> checked\n",
      "\n",
      "Uploading the dataset on VIP\n",
      "\n",
      "-----------------------------\n",
      "Cloning: data/quest_1job ... Already on VIP.\n",
      "-----------------------------\n",
      "Everything is on VIP.\n",
      "\n",
      ">> Session was saved in: vip_outputs/demo-single-job/session_data.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_session.upload_inputs(input_dir);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The session is automatically backed up in its output directory* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mvip_outputs\u001b[0m\n",
      "└── \u001b[01;34mdemo-single-job\u001b[0m\n",
      "    └── session_data.json\n",
      "\n",
      "1 directory, 1 file\n"
     ]
    }
   ],
   "source": [
    "! tree {Path(my_session.output_dir).parent} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"session_name\": \"demo-single-job\",\n",
      "    \"pipeline_id\": null,\n",
      "    \"local_input_dir\": \"data/quest_1job\",\n",
      "    \"local_output_dir\": \"vip_outputs/demo-single-job\",\n",
      "    \"vip_input_dir\": \"/vip/Home/API/demo-single-job/INPUTS\",\n",
      "    \"vip_output_dir\": \"/vip/Home/API/demo-single-job/OUTPUTS\",\n",
      "    \"input_settings\": null,\n",
      "    \"workflows\": {}\n",
      "}"
     ]
    }
   ],
   "source": [
    "! head {Path(my_session.output_dir) / \"session_data.json\"} "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch the pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Identifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show available pipelines on VIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available pipelines\n",
      "-------------------\n",
      "CQUEST/0.1.1\n",
      "CQUEST_fuzzy/0.1\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "VipSession.show_pipeline(\"cquest\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "App/Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_id = \"CQUEST/0.1.1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the pipeline description to know which inputs are required by the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "name: CQUEST | version: 0.1.1\n",
      "-----------------------------\n",
      "pipeline_id: CQUEST/0.1.1\n",
      "-----------------------------\n",
      "input_settings:\n",
      " - 'zipped_folder': [File] Archive containing the files listed in the parameter file\n",
      " - 'parameter_file': [File] File setting up constraints, options and prior knowledge used in cQuest algorithm\n",
      " - 'data_file': [File] File with extension and format of jMRUI containing the signal to quantify\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VipSession.show_pipeline(pipeline_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs can take several formats\n",
    "input_settings = { \n",
    "    \"zipped_folder\" : \"data/quest_1job/basis.zip\", # String\n",
    "    \"parameter_file\" : Path(input_dir) / \"parameters.txt\", # PathLib object\n",
    "    \"data_file\" : [\"data/quest_1job/signal.mrui\"] # List of strings / PathLib objects\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LAUNCH PIPELINE ===\n",
      "\n",
      "Pipeline ID: 'CQUEST/0.1.1' --> checked\n",
      "Input Settings --> parsed\n",
      "Parameter checks\n",
      "----------------\n",
      "Pipeline identifier: OK\n",
      "Output directory: OK\n",
      "Input settings: OK\n",
      "----------------\n",
      "\n",
      "Launching 1 new execution(s) on VIP\n",
      "-------------------------------------\n",
      "Execution Name: demo-single-job\n",
      "Started Workflows:\n",
      "\tworkflow-sPobH7, \n",
      "-------------------------------------\n",
      "Done.\n",
      "\n",
      ">> Session saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_session.launch_pipeline(pipeline_id, input_settings);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*See progression on https://vip.creatis.insa-lyon.fr/* ...\n",
    "\n",
    "... or monitor the workflow from this terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MONITOR WORKFLOW ===\n",
      "\n",
      "Updating worflow inventory ... Done.\n",
      "All executions are currently running on VIP.\n",
      "\n",
      "-------------------------------------------------------------\n",
      "The current proccess will wait until all executions are over.\n",
      "Their progress can be monitored on VIP portal:\n",
      "\thttps://vip.creatis.insa-lyon.fr/\n",
      "-------------------------------------------------------------\n",
      "All executions are over.\n",
      "All executions (1) ended with success.\n",
      "\n",
      ">> Session saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_session.monitor_workflows(refresh_time=2);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download your Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DOWNLOAD OUTPUTS ===\n",
      "\n",
      "Updating workflow status ... Done.\n",
      "\n",
      "Downloading pipeline outputs to: vip_outputs/demo-single-job\n",
      "--------------------------------\n",
      "[1/1] Outputs from: workflow-sPobH7 | Started on: 2023/06/13 20:08:04 | Status: Finished\n",
      "\tNew directory: vip_outputs/demo-single-job/13-06-2023_20:08:05\n",
      "\t[1/1] Downloading file (0.1MB): signal.mrui--parameters.txt.tgz ... Done.\n",
      "\t\tExtracting archive content ... Done.\n",
      "\tDone for all files.\n",
      "--------------------------------\n",
      "Done for all executions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_session.download_outputs();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If `output_dir` is not specified, results are stored at default location*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mvip_outputs/demo-single-job\u001b[0m\n",
      "├── \u001b[01;34m13-06-2023_20:08:05\u001b[0m\n",
      "│   └── \u001b[01;34msignal.mrui--parameters.txt.tgz\u001b[0m\n",
      "│       ├── \u001b[01;32mparameters.txt\u001b[0m\n",
      "│       ├── signal_Correlation.txt\n",
      "│       ├── \u001b[01;32msignal.mrui\u001b[0m\n",
      "│       ├── signal_quest2.txt\n",
      "│       ├── signal_quest_back.mrui\n",
      "│       ├── signal_quest_estim.mrui\n",
      "│       └── stdout_cquest.txt\n",
      "└── session_data.json\n",
      "\n",
      "2 directories, 8 files\n"
     ]
    }
   ],
   "source": [
    "! tree {my_session.output_dir}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelize your Jobs for Bigger Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Suppose we have more signals to analyse*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mdata/quest_2jobs\u001b[0m\n",
      "├── \u001b[01;31mbasis.zip\u001b[0m\n",
      "├── parameters.txt\n",
      "└── \u001b[01;34msignals\u001b[0m\n",
      "    ├── 001.mrui\n",
      "    └── 002.mrui\n",
      "\n",
      "1 directory, 4 files\n"
     ]
    }
   ],
   "source": [
    "new_dataset = Path(\"data/quest_2jobs\")\n",
    "! tree {new_dataset}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Lists_** of parameters launch **_parallel_** jobs on VIP (here in `data_file`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New input parameters for the pipeline\n",
    "new_settings = {\n",
    "    \"data_file\" : list((new_dataset / \"signals\").iterdir()),\n",
    "    \"parameter_file\" : new_dataset / \"parameters.txt\",\n",
    "    \"zipped_folder\" : new_dataset / \"basis.zip\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_settings = {\n",
      "  \"data_file\": [\n",
      "    \"data/quest_2jobs/signals/001.mrui\",\n",
      "    \"data/quest_2jobs/signals/002.mrui\"\n",
      "  ],\n",
      "  \"parameter_file\": \"data/quest_2jobs/parameters.txt\",\n",
      "  \"zipped_folder\": \"data/quest_2jobs/basis.zip\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Display the previous settings as strings to see the list of files\n",
    "import json\n",
    "print(\"new_settings =\",\n",
    "    json.dumps(indent=2, obj={\n",
    "        key: [str(v) for v in value] if isinstance(value, list) else str(value)\n",
    "            for key, value in new_settings.items()\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a new session with the new parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SESSION 'demo-parallel-jobs' ===\n",
      "\n",
      "Output directory: vip_outputs/demo-parallel-jobs\n",
      "Pipeline ID: 'CQUEST/0.1.1' --> checked\n",
      "Input Settings --> parsed\n",
      "Input Directory: 'data/quest_2jobs' --> checked\n",
      "\n",
      "\n",
      "=== UPLOAD INPUTS ===\n",
      "\n",
      "Checking references to the dataset within Input Settings ... \n",
      "\n",
      "OK.\n",
      "\n",
      "Uploading the dataset on VIP\n",
      "\n",
      "-----------------------------\n",
      "Cloning: data/quest_2jobs ... (Created on VIP)\n",
      "\t2 files to upload.\n",
      "\t[1/2] Uploading file: basis.zip (0.6MB) ... Done.\n",
      "\t[2/2] Uploading file: parameters.txt (0.0MB) ... Done.\n",
      "Cloning: data/quest_2jobs/signals ... (Created on VIP)\n",
      "\t2 files to upload.\n",
      "\t[1/2] Uploading file: 001.mrui (0.0MB) ... Done.\n",
      "\t[2/2] Uploading file: 002.mrui (0.0MB) ... Done.\n",
      "-----------------------------\n",
      "Everything is on VIP.\n",
      "\n",
      ">> Session was saved in: vip_outputs/demo-parallel-jobs/session_data.json\n",
      "\n",
      "\n",
      "=== LAUNCH PIPELINE ===\n",
      "\n",
      "Parameter checks\n",
      "----------------\n",
      "Pipeline identifier: OK\n",
      "Output directory: Created on VIP\n",
      "Input settings: OK\n",
      "----------------\n",
      "\n",
      "Launching 1 new execution(s) on VIP\n",
      "-------------------------------------\n",
      "Execution Name: demo-parallel-jobs\n",
      "Started Workflows:\n",
      "\tworkflow-wLwvYb, \n",
      "-------------------------------------\n",
      "Done.\n",
      "\n",
      ">> Session saved\n",
      "\n",
      "\n",
      "=== MONITOR WORKFLOW ===\n",
      "\n",
      "Updating worflow inventory ... Done.\n",
      "All executions are currently running on VIP.\n",
      "\n",
      "-------------------------------------------------------------\n",
      "The current proccess will wait until all executions are over.\n",
      "Their progress can be monitored on VIP portal:\n",
      "\thttps://vip.creatis.insa-lyon.fr/\n",
      "-------------------------------------------------------------\n",
      "All executions are over.\n",
      "All executions (1) ended with success.\n",
      "\n",
      ">> Session saved\n",
      "\n",
      "\n",
      "=== DOWNLOAD OUTPUTS ===\n",
      "\n",
      "Updating workflow status ... Done.\n",
      "\n",
      "Downloading pipeline outputs to: vip_outputs/demo-parallel-jobs\n",
      "--------------------------------\n",
      "[1/1] Outputs from: workflow-wLwvYb | Started on: 2023/06/13 20:10:25 | Status: Finished\n",
      "\tNew directory: vip_outputs/demo-parallel-jobs/13-06-2023_20:10:26\n",
      "\t[1/2] Downloading file (0.1MB): 001.mrui--parameters.txt.tgz ... Done.\n",
      "\t\tExtracting archive content ... Done.\n",
      "\t[2/2] Downloading file (0.1MB): 002.mrui--parameters.txt.tgz ... Done.\n",
      "\t\tExtracting archive content ... Done.\n",
      "\tDone for all files.\n",
      "--------------------------------\n",
      "Done for all executions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_session = VipSession(\n",
    "    session_name = \"demo-parallel-jobs\",\n",
    "    input_dir = new_dataset,\n",
    "    pipeline_id = \"CQUEST/0.1.1\",\n",
    "    input_settings = new_settings\n",
    ").run_session();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mvip_outputs/demo-parallel-jobs\u001b[0m\n",
      "├── \u001b[01;34m13-06-2023_20:10:26\u001b[0m\n",
      "│   ├── \u001b[01;34m001.mrui--parameters.txt.tgz\u001b[0m\n",
      "│   │   ├── 001_Correlation.txt\n",
      "│   │   ├── \u001b[01;32m001.mrui\u001b[0m\n",
      "│   │   ├── 001_quest2.txt\n",
      "│   │   ├── 001_quest_back.mrui\n",
      "│   │   ├── 001_quest_estim.mrui\n",
      "│   │   ├── \u001b[01;32mparameters.txt\u001b[0m\n",
      "│   │   └── stdout_cquest.txt\n",
      "│   └── \u001b[01;34m002.mrui--parameters.txt.tgz\u001b[0m\n",
      "│       ├── 002_Correlation.txt\n",
      "│       ├── \u001b[01;32m002.mrui\u001b[0m\n",
      "│       ├── 002_quest2.txt\n",
      "│       ├── 002_quest_back.mrui\n",
      "│       ├── 002_quest_estim.mrui\n",
      "│       ├── \u001b[01;32mparameters.txt\u001b[0m\n",
      "│       └── stdout_cquest.txt\n",
      "└── session_data.json\n",
      "\n",
      "3 directories, 15 files\n"
     ]
    }
   ],
   "source": [
    "! tree {new_session.output_dir}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat a Previous Experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resume previous session \"demo_single_job\" and relaunch it *as is*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SESSION 'demo-single-job' ===\n",
      "\n",
      "Output directory: vip_outputs/demo-single-job\n",
      "<< Session restored from its output directory\n",
      "\n",
      "\n",
      "=== UPLOAD INPUTS ===\n",
      "\n",
      "Skipped : There are already input data on VIP.\n",
      "\n",
      "=== LAUNCH PIPELINE ===\n",
      "\n",
      "Parameter checks\n",
      "----------------\n",
      "Pipeline identifier: OK\n",
      "Output directory: OK\n",
      "Input settings: OK\n",
      "----------------\n",
      "\n",
      "Launching 1 new execution(s) on VIP\n",
      "-------------------------------------\n",
      "Execution Name: demo-single-job\n",
      "Started Workflows:\n",
      "\tworkflow-v0T4Ux, \n",
      "-------------------------------------\n",
      "Done.\n",
      "\n",
      ">> Session saved\n",
      "\n",
      "\n",
      "=== MONITOR WORKFLOW ===\n",
      "\n",
      "Updating worflow inventory ... Done.\n",
      "1 execution(s) ended with success:\n",
      "\t workflow-sPobH7 , started on: 2023/06/13 20:08:04\n",
      "1 execution(s) is/are currently running on VIP:\n",
      "\t workflow-v0T4Ux , started on: 2023/06/13 20:13:11\n",
      "\n",
      "-------------------------------------------------------------\n",
      "The current proccess will wait until all executions are over.\n",
      "Their progress can be monitored on VIP portal:\n",
      "\thttps://vip.creatis.insa-lyon.fr/\n",
      "-------------------------------------------------------------\n",
      "All executions are over.\n",
      "All executions (2) ended with success.\n",
      "\n",
      ">> Session saved\n",
      "\n",
      "\n",
      "=== DOWNLOAD OUTPUTS ===\n",
      "\n",
      "Updating workflow status ... Done.\n",
      "\n",
      "Downloading pipeline outputs to: vip_outputs/demo-single-job\n",
      "--------------------------------\n",
      "[1/2] Outputs from: workflow-sPobH7 | Started on: 2023/06/13 20:08:04 | Status: Finished\n",
      "\tAlready in: vip_outputs/demo-single-job/13-06-2023_20:08:05\n",
      "[2/2] Outputs from: workflow-v0T4Ux | Started on: 2023/06/13 20:13:11 | Status: Finished\n",
      "\tNew directory: vip_outputs/demo-single-job/13-06-2023_20:13:13\n",
      "\t[1/1] Downloading file (0.1MB): signal.mrui--parameters.txt.tgz ... Done.\n",
      "\t\tExtracting archive content ... Done.\n",
      "\tDone for all files.\n",
      "--------------------------------\n",
      "Done for all executions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VipSession(\"demo-single-job\").run_session(update_files=False, refresh_time=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mvip_outputs/demo-single-job\u001b[0m\n",
      "├── \u001b[01;34m13-06-2023_20:08:05\u001b[0m\n",
      "│   └── \u001b[01;34msignal.mrui--parameters.txt.tgz\u001b[0m\n",
      "│       ├── \u001b[01;32mparameters.txt\u001b[0m\n",
      "│       ├── signal_Correlation.txt\n",
      "│       ├── \u001b[01;32msignal.mrui\u001b[0m\n",
      "│       ├── signal_quest2.txt\n",
      "│       ├── signal_quest_back.mrui\n",
      "│       ├── signal_quest_estim.mrui\n",
      "│       └── stdout_cquest.txt\n",
      "├── \u001b[01;34m13-06-2023_20:13:13\u001b[0m\n",
      "│   └── \u001b[01;34msignal.mrui--parameters.txt.tgz\u001b[0m\n",
      "│       ├── \u001b[01;32mparameters.txt\u001b[0m\n",
      "│       ├── signal_Correlation.txt\n",
      "│       ├── \u001b[01;32msignal.mrui\u001b[0m\n",
      "│       ├── signal_quest2.txt\n",
      "│       ├── signal_quest_back.mrui\n",
      "│       ├── signal_quest_estim.mrui\n",
      "│       └── stdout_cquest.txt\n",
      "└── session_data.json\n",
      "\n",
      "4 directories, 15 files\n"
     ]
    }
   ],
   "source": [
    "! tree {VipSession(\"demo-single-job\", verbose=False).output_dir}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Temporary Data from VIP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*After the download, **your input and output data are still on VIP** (https://vip.creatis.insa-lyon.fr/)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/vip/Home/API/demo-single-job/INPUTS',\n",
       " '/vip/Home/API/demo-single-job/OUTPUTS')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_session.vip_input_dir, my_session.vip_output_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Please remove your temporary data when a session is over.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SESSION 'demo-single-job' ===\n",
      "\n",
      "Output directory: vip_outputs/demo-single-job\n",
      "<< Session restored from its output directory\n",
      "\n",
      "\n",
      "=== FINISH ===\n",
      "\n",
      "Ending Session: demo-single-job\n",
      "Removing session data\n",
      "---------------------\n",
      "[vip] /vip/Home/API/demo-single-job ... Done.\n",
      "---------------------\n",
      "\n",
      "Updating workflows status\n",
      "-------------------------\n",
      "workflow-sPobH7: Removed\n",
      "workflow-v0T4Ux: Removed\n",
      "-------------------------\n",
      "All output data have been removed from VIP.\n",
      "Session 'demo-single-job' is now over.\n",
      "\n",
      ">> Session saved\n",
      "\n",
      "\n",
      "=== SESSION 'demo-parallel-jobs' ===\n",
      "\n",
      "Output directory: vip_outputs/demo-parallel-jobs\n",
      "<< Session restored from its output directory\n",
      "\n",
      "\n",
      "=== FINISH ===\n",
      "\n",
      "Ending Session: demo-parallel-jobs\n",
      "Removing session data\n",
      "---------------------\n",
      "[vip] /vip/Home/API/demo-parallel-jobs ... Done.\n",
      "---------------------\n",
      "\n",
      "Updating workflows status\n",
      "-------------------------\n",
      "workflow-wLwvYb: Removed\n",
      "-------------------------\n",
      "All output data have been removed from VIP.\n",
      "Session 'demo-parallel-jobs' is now over.\n",
      "\n",
      ">> Session saved\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.VipSession.VipSession at 0x7f4f5c3acac0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VipSession(\"demo-single-job\").finish()\n",
    "VipSession(\"demo-parallel-jobs\").finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The output data downloaded on your computer is yours to remove*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r vip_outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
